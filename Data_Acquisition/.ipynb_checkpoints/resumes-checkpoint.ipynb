{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95161c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e68490cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analyst', 'Project Management Intern', 'Database Developer/Systems Administrator, Intern', 'C++ (3 years)', 'JAVASCRIPT (4 years)', 'Python (5 years)', 'Data Visualization (4 years)', 'SQL (5 years)', 'Data Analysis (3 years)', 'Machine Learning (2 years)', 'Deep Learning (1 year)', 'Applied Statistics (2 years)', 'Data Mining (2 years)', 'Software Engineering (2 years)', 'R (2 years)', 'Big Data', 'Data Science', 'Business Intelligence', 'SAP', 'Excel', 'HTML', 'C# (2 years)', '.NET (2 years)', 'TensorFlow (1 year)', 'Neural Networks (Less than 1 year)', 'Keras (Less than 1 year)', 'Torch (Less than 1 year)', 'PySpark (Less than 1 year)']\n",
      "000000000000000\n",
      "['Business Intelligence', 'BI']\n",
      "000000000000000\n",
      "['Energy Services Analyst', 'Marketing Coordinator - Contract', 'Co-Founder and Front- End Developer', 'Associate Technical Recruiter', 'Excel', 'SQL', 'Powerpoint', 'Microsoft Office', 'Business Intelligence']\n",
      "000000000000000\n",
      "['Data Architect', 'Senior Data Analyst, Interim IT Manager', 'Business Analyst/ Project Coordinator', 'linear regression (1 year)', 'Lotus Notes (Less than 1 year)', 'NetSuite (1 year)', 'Python (Less than 1 year)', 'testing (1 year)', 'Excel', 'SQL']\n",
      "000000000000000\n",
      "['IT, Cyber security Trainee', 'IT Trainee', 'Statistical Data Analysis (A/B testing, regression), Corporate Finance, Management, Global Business and Leadership, Network Architecture and security, Algorithm performance design, Database, Matlab, R, Mathematica, Shell scripting, Full stack web developer and Ocaml, Bilingual English & French']\n",
      "000000000000000\n",
      "['Pandas (3 years)', 'Scikit learn (3 years)', 'Python (3 years)', 'Nltk (2 years)', 'SQL (3 years)', 'Hadoop (1 year)', 'Machine Learning', 'Spark', 'Big Data', 'NLP', 'Excel', 'Microsoft Office', 'Business Intelligence']\n",
      "000000000000000\n",
      "['Research Assistant (Python, Terrier Search Engine)', 'Git', 'Hadoop', 'Hive', 'PYTHON', 'KERAS', 'MATPLOTLIB', 'NUMPY', 'PANDAS', 'TENSORFLOW', 'MACHINE LEARNING', 'HADOOP', 'NLP', 'MYSQL', 'POSTGRESQL', 'JAVA', 'SQL', 'NLTK', 'Keras', 'Scikit-Learn', 'Gensim', 'AWS', 'Stanford CoreNLP', 'Hypothesis Testing', 'Spark', 'R']\n",
      "000000000000000\n",
      "['Oracle 10g', 'Pl/sql', 'Sql', 'Eclipse', 'Java J2Ee', 'Java', 'Hibernate', 'Spring', 'JSP']\n",
      "000000000000000\n",
      "['NETWORK ADMINISTRATOR/SERVICE TECHNICIAN', 'C/C++', 'C++', 'JAVASCRIPT', 'D3.JS', 'PYTHON', 'NUMPY', 'PANDAS', 'DYNAMODB', 'MACHINE LEARNING', 'NOSQL', 'SQL', 'SELENIUM', 'DEPLOYMENT', 'VISUALIZATION', 'STATISTICS']\n",
      "000000000000000\n",
      "['Data Analyst - Python Developer', 'Amazon web services', 'Hadoop', 'Hdfs', 'Mapreduce', 'Python', 'Ggplot2', 'Matplotlib', 'Anova', 'Mapreduce', 'Kafka', 'Data visualization', 'Hadoop', 'Mongodb', 'Database', 'Microsoft sql server', 'Sql server', 'Mysql', 'Oracle', 'Postgresql', 'Sql']\n",
      "000000000000000\n",
      "['PYTHON DEVELOPER', 'Python', 'Microsoft Office', 'Excel', 'SQL', 'R programming', 'Machine learning', 'Deep Learning', 'Hadoop', 'MS Office', 'Powerpoint', 'access']\n",
      "000000000000000\n",
      "['PYTHON DEVELOPER', 'Linux', 'Business Intelligence', 'SQL', 'Statistical analysis', 'NLP', 'AWS', 'Python', 'HIVE/SQL']\n",
      "000000000000000\n",
      "['Data Analyst', 'Java Developer']\n",
      "000000000000000\n",
      "['Data Analyst', 'Python Developer / Data Analyst', 'ETL Developer']\n",
      "000000000000000\n",
      "['Python Developer / Data Analyst', 'ETL Developer']\n",
      "000000000000000\n",
      "['Python Developer', 'Data Analyst', 'Business Intelligence', 'SQL', 'access', 'testing', 'Excel', 'Data Science (9 years)', 'Python (9 years)']\n",
      "000000000000000\n",
      "['Data Analyst - Python Developer', 'Amazon web services', 'Hadoop', 'Hdfs', 'Mapreduce', 'Python', 'Ggplot2', 'Matplotlib', 'Anova', 'Mapreduce', 'Kafka', 'Data visualization', 'Hadoop', 'Mongodb', 'Snowflake schema', 'Data modeling', 'Database', 'Microsoft sql server', 'Sql server', 'Mysql', 'Oracle']\n",
      "000000000000000\n",
      "['Data Analyst', 'Python Developer / Data Analyst', 'ETL Developer']\n",
      "000000000000000\n",
      "['Data analyst', 'Data Analyst', 'Python Developer', 'Data Analyst']\n",
      "000000000000000\n",
      "['Data analyst', 'Data Analyst', 'Python Developer', 'Data Analyst']\n",
      "000000000000000\n",
      "['Data analyst', 'Data Analyst', 'Python Developer', 'Data Analyst', 'SQL']\n",
      "000000000000000\n",
      "['Data Scientist', 'Python Developer', 'Data Analyst', 'Data Analyst', 'APACHE CASSANDRA (1 year)', 'APACHE HBASE (1 year)', 'ASTERADATA (1 year)', 'Cassandra (1 year)', 'database (5 years)', 'databases (1 year)', 'Excel (5 years)', 'HBase (1 year)', 'Linux (2 years)', 'Matlab (2 years)', 'MongoDB (1 year)', 'MS Office (2 years)', 'MS SQL SERVER (2 years)', 'Python (5 years)', 'Scala (1 year)', 'SQL (7 years)', 'SQL Server (2 years)', 'UNIX (3 years)', 'Visio (2 years)', 'XML (1 year)']\n",
      "000000000000000\n",
      "['CSS (Less than 1 year)', 'DATABASE (Less than 1 year)', 'Python (2 years)', 'HTML 5 (Less than 1 year)', 'Java (Less than 1 year)', 'Javascript (Less than 1 year)', 'R (Less than 1 year)', 'Django', 'AWS', 'Linux', 'Numpy']\n",
      "000000000000000\n",
      "['Data Analyst- Python', 'SQL Developer', 'Python 3.2/2.7, hive, oozie, Tableau, Informatica 9.0, HTML5, CSS, XML, MySQL, MS SQL Server 2008/2012, JavaScript, AWS, S3, EC2, Linux, Jupyter Notebook, RNN, ANN, Spark, Hadoop (8 years)']\n",
      "000000000000000\n",
      "['Data Scientist', 'SQL Developer', 'SQL', 'Business Intelligence', 'access', 'testing', 'Excel', 'Python 3.2/2.7, hive, Tableau, R, QlikView, MySQL, MS SQL Server 2008/2012, AWS, S3, EC2, Linux, Jupyter Notebook, RNN, ANN, Spark, Hadoop. (8 years)']\n",
      "000000000000000\n",
      "['Data Analyst', 'Data Analyst', 'Data Analyst/ Python Developer', 'CASSANDRA', 'HDFS', 'IMPALA', 'MAPREDUCE', 'SQOOP', 'HBASE', 'KAFKA', 'ELASTICSEARCH', 'ETL', 'FLUME', 'HADOOP', 'INFORMATICA', 'MONGODB', 'NLP', 'REDIS', 'TABLEAU SERVER', 'TERADATA', 'DATA MODELING', 'DATABASE', 'DATABASE DESIGN']\n",
      "000000000000000\n",
      "['Data Modeler/Data Analyst', 'Python Developer', 'Data Analyst/Data Modeler', 'Linux', 'Solaris', 'Sun', 'Unix']\n",
      "000000000000000\n",
      "['Data Modeler/Data Analyst', 'Python Developer', 'Data Analyst/Data Modeler', 'LINUX', 'SOLARIS', 'SUN', 'UNIX']\n",
      "000000000000000\n",
      "['Python Tutorial Writer', 'Visiting Research Intern - Advisor S. Scherer', 'Natural Language Processing Consultant', 'Research Assistant - Advisor A. Rosenberg', 'Fellow', 'Methods in Computational Linguistics Graduate Assistant', 'Advanced Syntax Graduate Assistant', 'Adult ESL Teacher', 'High School ESL Teacher', 'Elementary School ESL Teacher']\n",
      "000000000000000\n",
      "['Big Data Developer', 'Python Developer', 'PYTHON (7 years)', 'MACHINE LEARNING (5 years)', 'Hadoop (3 years)', 'HADOOP (3 years)', 'DEEP LEARNING (1 year)']\n",
      "000000000000000\n",
      "['Java Developer', 'PHP/MySQL Developer', 'C++ Developer', 'iOS/Swift Developer', 'Python (2 years)', 'Java (2 years)', 'PHP (1 year)']\n",
      "000000000000000\n",
      "['Data Analyst', 'Python Developer / Data Analyst', 'ETL Developer']\n",
      "000000000000000\n",
      "['Senior Python Software Engineer /Data Scientist', 'Cassandra', 'Impala', 'Mapreduce', 'Hbase', 'Kafka']\n",
      "000000000000000\n",
      "['Lead .NET/ Python Developer', 'Senior .NET Software Engineer', 'Senior .NET Software Engineer', 'Senior Software Engineer', 'Software Engineer', '.NET (10+ years)', 'Apache (4 years)', 'machine learning (5 years)', 'Python. (5 years)', 'SQL (10+ years)', 'R (5 years)', 'Azure Databricks (2 years)', 'Keras (3 years)', 'Azure ML Studio (3 years)', 'Hadoop (2 years)', 'Python', 'Big Data', 'NLP (3 years)', 'Spark (2 years)', 'Data Science (7 years)', 'Java (2 years)', 'Kubernetes (2 years)', 'Neo4J (2 years)', 'Docker (2 years)']\n",
      "000000000000000\n",
      "['SENIOR ENGINEER/LEAD ENGINEER (LINUX & WINDOWS)', 'DATA SCIENTIST', 'RESTORATION SHOP VOLUNTEER', 'SENIOR RESEARCH ANALYST (ADVANCED EXCEL, S & S-PLUS)', 'SENIOR VICE PRESIDENT (C, VISUAL BASIC & ADVANCED EXCEL)', 'SENIOR ASSOCIATE, CONSULTANT (RATS & VISUAL BASIC)', 'EXPERIENCED SENIOR CONSULTANT (ADVANCED EXCEL, C++)', 'SENIOR RESEARCH ASSOCIATE (ADVANCED EXCEL)', 'SENIOR ANALYST, SYSTEMS MANAGER (SAS)']\n",
      "000000000000000\n",
      "['Senior SAS Quantitative Data Analyst / Software Developer / Project Consultant', 'Senior SAS Data Science and Machine Learning Project Consultant', 'Senior SAS Data Scientist / Machine Learning Credit Risk Statistical Modelling Project Consultant', 'Senior SAS Data Scientist / Machine Learning Marketing Data Analyst Project Consultant', 'Senior SAS Reports Developer and Quantitative Digital Marketing Data Analyst Project Consultant', 'Senior SAS Machine Learning Data Scientist / Mobility Data Analyst / Software Developer', 'Tax Technology Project Consultant', 'Database Marketing Project Consultant', 'Senior SAS Data Scientist / Machine Learning Statistical Modeller and Software Developer', 'SAS Developer Project Consultant', 'Statistical SAS Programming and Analysis / Quantitative Database Marketing Project Consultant', 'SAS Data Scientist and Machine Learning Database Marketing ROI Consultant', 'Vice President, Project Manager - Marketing', 'Director of Programming', 'Assistant Vice President, Credit Risk Forecasting Analyst', 'Database Marketing Manager', 'Senior SAS Programming Marketing Project Consultant', 'Senior Marketing Data Scientist / Machine Learning SAS Software Developer', 'Market Analyst', 'Statistician / Data Scientist Consultant', 'International Economist', 'SAS Marketing Data Scientist and Predictive Machine Learning Modelling Forecaster', 'PIVOT TABLES', 'SAS', 'UNIX', 'COGNOS', 'MS PROJECT', 'MICROSTRATEGY', 'OLAP', 'SPOTFIRE', 'TABLEAU', 'TERADATA', 'DB2', 'SQL SERVER', 'MYSQL', 'ORACLE', 'PL/SQL', 'SQL', 'STORED PROCEDURES', 'UDB', 'VSAM', 'CMS']\n",
      "000000000000000\n",
      "['Python Developer / Data Analyst', 'Business Data Analyst', 'Python Developer', 'C/c++', 'C++', 'Hadoop', 'Ms project', 'Python', 'Vba', 'Visio', 'Database', 'Database systems', 'Ms access', 'Mysql', 'Postgresql', 'Tableau', 'Data science', 'Hadoop', 'Machine learning', 'Nlp', 'Deep learning', 'Neural networks', 'Linux']\n",
      "000000000000000\n",
      "['Python Developer', 'Python Developer', 'Hadoop Developer', 'Java Developer', 'PYTHON (10+ years)', 'MYSQL (10+ years)', 'ORACLE (10+ years)', 'PL/SQL (10+ years)', 'SQL (10+ years)']\n",
      "000000000000000\n",
      "['Python developer', 'algorithms (8 years)', 'API (5 years)', 'Machine Learning (10+ years)', 'python. (10+ years)', 'SQL (10+ years)', ' Expertise: Scikit-learn, NLTK, spaCy, NumPy, SciPy, OpenCv, Deep learning, NLP, RNN, CNN, Tensor flow, Keras, matplotlib, Microsoft Visual Studio, Microsoft Office. (10+ years)']\n",
      "000000000000000\n",
      "['Python developer', 'algorithms (8 years)', 'API (5 years)', 'Machine Learning (10+ years)', 'python. (10+ years)', 'SQL (10+ years)', 'Machine learning, AWS, MS Azure, Cassandra, SAS, Spark, HDFS, Hive, Pig, Linux, Anaconda Python , MySQL, Eclipse, PL/SQL, SQL connector, SparkML.']\n",
      "000000000000000\n",
      "['Python developer', 'CLUSTERING', 'DATA VISUALIZATION', 'ELASTICSEARCH', 'HADOOP', 'MACHINE LEARNING', ' Expertise: Scikit-learn, NLTK, spaCy, NumPy, SciPy, OpenCv, Deep learning, NLP, RNN, CNN, Tensor flow, Keras, matplotlib, Microsoft Visual Studio, Microsoft Office. (8 years)']\n",
      "000000000000000\n",
      "['Data Scientist', 'Python Developer', 'Programmer Analyst', 'Android. (Less than 1 year)', 'Application development (Less than 1 year)', 'Bi (Less than 1 year)', 'Data warehouse (Less than 1 year)', 'Linux (6 years)']\n",
      "000000000000000\n",
      "['School Site Council Chairperson', 'Instructor', 'Python', 'SQL', 'Teaching', 'Data Analysis']\n",
      "000000000000000\n",
      "['Data Science Analyst', 'Data Analyst', 'Data Analyst/ Python Developer', 'APACHE HADOOP HDFS (5 years)', 'HADOOP DISTRIBUTED FILE SYSTEM (5 years)', 'HDFS (5 years)', 'Python (7 years)', 'SQL (6 years)']\n",
      "000000000000000\n",
      "['Data Scientist', 'Analyst/Data Scientist', 'Jr. Python Developer', 'ALGORITHMS (10+ years)', 'BI (10+ years)', 'BUSINESS INTELLIGENCE (10+ years)', 'LINUX (10+ years)', 'LOGISTIC REGRESSION (10+ years)']\n",
      "000000000000000\n",
      "['Data Analyst', 'Python Developer', 'SQL (10+ years)', 'APACHE HADOOP MAPREDUCE (8 years)', 'MapReduce (8 years)', 'MAPREDUCE (8 years)', 'PL/SQL (8 years)']\n",
      "000000000000000\n",
      "['Data Scientist', 'Data Scientist', 'Data Scientist', 'Python Developer', 'Programmer Analyst', 'APPLICATION DEVELOPMENT', 'TABLEAU (8 years)', 'LINUX (5 years)', 'SAP (1 year)', 'BI (1 year)', 'Python', 'R', 'Hadoop', 'Machine Learning', 'Spark']\n",
      "000000000000000\n",
      "['Software Engineer', 'System Architect / Researcher / Java .NET Python Developer', 'Consultant', 'Desktop Support Engineer', 'B2B SOFTWARE (7 years)', 'Software Development (10+ years)', 'PYTHON (8 years)', 'Data Analysis (6 years)', 'Data Mining (6 years)', 'Manager (3 years)']\n",
      "000000000000000\n",
      "['Python Developer/Data Scientist', 'Geophysical Data Scientist', 'Data Scientist/Advanced Software Engineer', 'Seismic Data Processor', 'Financial Analyst', 'Python, Java, R, SAS, SQL, Hadoop, Hive, Spark, Tensorflow, bigDL, Machine Learning, Deep Learning (7 years)', 'Python', 'Hadoop', 'Machine Learning', 'R', 'Spark']\n",
      "000000000000000\n",
      "['Managing Principal', 'Software Developer', 'Research Scientist', 'Contractor', 'Lecturer', 'Assistant Professor', 'Postdoctoral Fellow and Lecturer', 'Postdoctoral Fellow and Lecturer', 'Python (5 years)', 'Linux (10+ years)', 'Machine Learning, Data Mining, Signal Processing, Algorithmic Trading, UNIX Administration, Scientific Programming, High-Performance Computing, Numerical Analysis, Applied Mathematics', 'ArcGIS (3 years)', 'Research (10+ years)', 'Statistical Analysis (10+ years)']\n",
      "000000000000000\n",
      "['Software Developer Intern', 'Python (scipy, numpy, keras, pandas, scikit-learn, matplotlib) (3 years)', 'Matlab (2 years)', 'Java (2 years)', 'Apache Spark (Less than 1 year)', 'Keras (1 year)', 'Tensorflow (1 year)', 'R (1 year)', 'AWS EC2 (Less than 1 year)', 'Python', 'Hadoop (Less than 1 year)', 'AWS', 'MYSQL', 'Git']\n",
      "000000000000000\n",
      "['Research Assistant ( Python, Terrier Search Engine)', 'Git', 'Hadoop', 'Hive', 'PYTHON', 'KERAS', 'MATPLOTLIB', 'NUMPY', 'PANDAS', 'TENSORFLOW', 'MACHINE LEARNING', 'HADOOP', 'NLP', 'MYSQL', 'POSTGRESQL', 'JAVA', 'SQL', 'NLTK', 'Keras', 'Scikit-Learn', 'Gensim', 'AWS', 'Stanford CoreNLP', 'Hypothesis Testing', 'Spark', 'R']\n",
      "000000000000000\n",
      "['Clustering', 'Hadoop', 'Data analysis', 'Mysql', 'Sql', 'Git', 'Hadoop', 'Json', 'Mapreduce', 'Python', 'Ggplot2', 'Matplotlib', 'Numpy', 'Pandas', 'Shiny', 'Anova', 'Boosting', 'Decision trees', 'Dimensionality reduction']\n",
      "000000000000000\n",
      "['Programmer/Designer/Product Manager - Senior Design', 'Programmer/Designer']\n",
      "000000000000000\n",
      "[]\n",
      "000000000000000\n",
      "['Graduate Teaching Assistant', 'Programmer/Designer']\n",
      "000000000000000\n",
      "['Python Developer', 'PYTHON (3 years)', 'MATPLOTLIB (1 year)', 'NUMPY (3 years)', 'MACHINE LEARNING (3 years)', 'SQL (2 years)', 'Visio', 'Business Intelligence', 'Microsoft Office', 'Excel', 'HTML', 'testing', 'Deep Learning (1 year)', 'NLP (Less than 1 year)', 'Tensorflow (Less than 1 year)', 'PyTorch (Less than 1 year)', 'Regression (1 year)', 'Random Forest (1 year)']\n",
      "000000000000000\n",
      "['testing', 'Excel', 'Business Intelligence', 'access', 'SQL']\n",
      "000000000000000\n",
      "['Data Analyst', 'Python Developer', 'APACHE HADOOP HDFS (3 years)', 'Oracle (3 years)', 'python. (3 years)', 'SQL (4 years)', 'XML (3 years)']\n",
      "000000000000000\n",
      "['Dragon Research Intern - Data Processing Tool Developer', 'Python Developer']\n",
      "000000000000000\n",
      "['.NET (4 years)', 'C+ (4 years)', 'Matlab (3 years)', 'Python (3 years)', 'Visual Studio (4 years)']\n",
      "000000000000000\n",
      "['.net (4 years)', 'Auto cad (Less than 1 year)', 'C+ (4 years)', 'Cad (Less than 1 year)', 'database. (Less than 1 year)', 'Ethernet (Less than 1 year)', 'Git (Less than 1 year)', 'image processing (1 year)', 'Java (Less than 1 year)', 'Linux (Less than 1 year)', 'Mac (Less than 1 year)', 'macos (Less than 1 year)', 'Matlab (3 years)', 'Mysql. (3 years)', 'Open gl (Less than 1 year)', 'Opengl. (Less than 1 year)', 'Pcl (Less than 1 year)', 'Perforce (Less than 1 year)', 'Python (3 years)', 'Visual studio (4 years)']\n",
      "000000000000000\n",
      "['.NET (4 years)', 'AUTO CAD (Less than 1 year)', 'C+ (4 years)', 'CAD (Less than 1 year)', 'database. (Less than 1 year)', 'Ethernet (Less than 1 year)', 'Git (Less than 1 year)', 'image processing (1 year)', 'Java (Less than 1 year)', 'Linux (Less than 1 year)', 'MAC (Less than 1 year)', 'macOS (Less than 1 year)', 'Matlab (3 years)', 'MySQL. (3 years)', 'OPEN GL (Less than 1 year)', 'OpenGL. (Less than 1 year)', 'PCL (Less than 1 year)', 'Perforce (Less than 1 year)', 'Python (3 years)', 'Visual Studio (4 years)']\n",
      "000000000000000\n",
      "['Senior Research Assistant ( Python Developer)', 'Data Czar (Data Analyst)', 'Software Engineer', 'JAVASCRIPT (3 years)', 'PYTHON (3 years)', 'SQL (3 years)', 'JAVA (3 years)', 'jQuery (3 years)', 'Excel', 'Data Entry', 'Data Analysis', 'Tableau', 'ETL', 'R programming (2 years)', 'SAS (1 year)', 'HTML', 'Microsoft Office', 'Powerpoint']\n",
      "000000000000000\n",
      "['Software Developer Intern', 'Python (scipy, numpy, keras, pandas, scikit-learn, matplotlib) (3 years)', 'Matlab (2 years)', 'Java (2 years)', 'Apache Spark (Less than 1 year)', 'Keras (1 year)', 'Tensorflow (1 year)', 'R (1 year)', 'AWS EC2 (Less than 1 year)', 'Python', 'Hadoop (Less than 1 year)', 'AWS', 'MYSQL', 'Git']\n",
      "000000000000000\n",
      "['Data Analyst', 'Project Management Intern', 'Database Developer/ Systems Administrator, Intern', 'C++ (3 years)', 'JAVASCRIPT (4 years)', 'Python (5 years)', 'Data Visualization (4 years)', 'SQL (5 years)', 'Data Analysis (3 years)', 'Machine Learning (2 years)', 'Deep Learning (1 year)', 'Applied Statistics (2 years)', 'Data Mining (2 years)', 'Software Engineering (2 years)', 'R (2 years)', 'Big Data', 'Data Science', 'Business Intelligence', 'SAP', 'Excel', 'HTML', 'C# (2 years)', '.NET (2 years)', 'TensorFlow (1 year)', 'Neural Networks (Less than 1 year)', 'Keras (Less than 1 year)', 'Torch (Less than 1 year)', 'PySpark (Less than 1 year)']\n",
      "000000000000000\n",
      "['Data Analyst', 'Data Analyst', 'Data Analyst', 'Db2', 'Microsoft sql server', 'Microsoft sql server 2008', 'Sql server', 'Sql server 2008', 'Mysql', 'Oracle', 'Sql', 'Cassandra', 'Hdfs', 'Impala', 'Mapreduce', 'Oozie', 'Sqoop', 'Hbase', 'Kafka', 'Flume', 'Hadoop', 'Mongodb', 'Splunk']\n",
      "000000000000000\n"
     ]
    }
   ],
   "source": [
    "path = '../datasets/resume_samples.txt'\n",
    "with open(path, 'r',encoding=\"utf8\", errors='ignore') as f:\n",
    "    for line in f.readlines():\n",
    "        splitted = line.split(':::')[1]\n",
    "        splitted = splitted.split(';')\n",
    "        title = splitted[0]\n",
    "        skills = splitted[3:]\n",
    "        if 'data scientist' in title.lower():\n",
    "            print(skills)\n",
    "            print('000000000000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d41876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "67\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "for line in resumes[:10]:\n",
    "    print(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed44481a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-edd8fbbf9070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msplit_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':::'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':::'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    header = row.iloc[0]\n",
    "    if type(header)==str:\n",
    "        split_title = (header.split(':::'))[1].split(';')\n",
    "        title = header.split(':::')[1].split(';')[0]\n",
    "        skills = header.split(':::')[1]\n",
    "        skills = header.split(';')[2:]\n",
    "        #if len(skills)>2:\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759033a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_bert(string):\n",
    "    string = string.strip(\"\\n.’:\")\n",
    "    string = string.strip(\"’\")\n",
    "    string = string.strip(\"\\\\n\")\n",
    "    string = string.replace(\"/\",\" \")\n",
    "    return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k21 = pickle.load(open('../Experiments/k21.sav', 'rb'))\n",
    "objectives = []\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99863d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194cfbf937a645788bdeeeb52bf61915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c752a2a2811435695188307fb5eb7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088b1c7360a549f9b6256a307ac4471f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10a000843b7454aabe887d11e217efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94427d9646c04ad3a3b3367fee4ad0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56059648181446f79ed3e67219bcc3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c37eb5f594946999b4e1570ed1183b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fcab6f3fdf470bb80fe24b42fca54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5767ca7bd34a058fa51988701143cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e460ca7b834080948f123ca57bcdab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6aff8801e3c4566be205ebddac0c030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d14576fb3314ab195a8ba464130ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for o in df['objective'].to_list():\n",
    "    objectives.append(preprocess_for_bert(o))\n",
    "embeddings = model.encode(objectives)\n",
    "clusters =  k21.predict(np.array(embeddings.tolist()))\n",
    "df['clusters']=clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bde631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k20_bigrams = pickle.load(open('../Experiments/k20_bigrams', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c2929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "for cluster in clusters:\n",
    "    bigrams.append(k20_bigrams[cluster])\n",
    "df['bigrams_k20']=bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "650b3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale\n",
    "#handy pandas visualizer, when on local Jupyter Server just run dtale.show(df)\n",
    "#from Docker container visual is available at http://localhost:40000/\n",
    "d=dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afdf53f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objective</th>\n",
       "      <th>module</th>\n",
       "      <th>study_program</th>\n",
       "      <th>clusters</th>\n",
       "      <th>bigrams_k20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understand the fundamental building blocks of ...</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analyze stochastic data in terms of the underl...</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utilize Bayesian statistics techniques.</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summarize the properties of observed data usin...</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apply data visualization techniques to design ...</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>15</td>\n",
       "      <td>data visualization, large datasets, experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>evaluate model parameters using parameter esti...</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>create hypothesis tests to discriminate betwee...</td>\n",
       "      <td>Advanced Statistics</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>analyze use cases and their requirements regar...</td>\n",
       "      <td>Use Case and Evaluation</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>17</td>\n",
       "      <td>multiple projects, r&amp;d projects, project team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>apply common metrics to evaluate predictions.</td>\n",
       "      <td>Use Case and Evaluation</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>evaluate key performance indicators to asses p...</td>\n",
       "      <td>Use Case and Evaluation</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>17</td>\n",
       "      <td>multiple projects, r&amp;d projects, project team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>create monitoring tools that can be used to co...</td>\n",
       "      <td>Use Case and Evaluation</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>understand common fallacies and how to avoid t...</td>\n",
       "      <td>Use Case and Evaluation</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>18</td>\n",
       "      <td>working people, problem solving, lifestyle cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>identify current research trends and topics in...</td>\n",
       "      <td>Seminar: Current Topics in Data Science</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>13</td>\n",
       "      <td>data science, data engineering, experience dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>outline a selected topic in the form of a writ...</td>\n",
       "      <td>Seminar: Current Topics in Data Science</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>18</td>\n",
       "      <td>working people, problem solving, lifestyle cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>explain relevant assumptions and design choice...</td>\n",
       "      <td>Seminar: Current Topics in Data Science</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>18</td>\n",
       "      <td>working people, problem solving, lifestyle cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>relate the chosen topic to comparable approaches.</td>\n",
       "      <td>Seminar: Current Topics in Data Science</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>name and describe potential applications for t...</td>\n",
       "      <td>Seminar: Current Topics in Data Science</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>17</td>\n",
       "      <td>multiple projects, r&amp;d projects, project team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>know different machine learning model classes.</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>comprehend the difference between supervised, ...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>understand common machine learning models.</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>analyze trade-offs in the application of diffe...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>appropriately choose machine learning models a...</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>comprehend the fundamental building blocks of ...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>understand concepts in deep learning.</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>analyze the relevant deep learning architectur...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>create deep learning models.</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>utilize alternative methods to train deep lear...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>understand current data science methodologies.</td>\n",
       "      <td>Case Study: Model Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>13</td>\n",
       "      <td>data science, data engineering, experience dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>devaluate the quality of the data used in data...</td>\n",
       "      <td>Case Study: Model Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>13</td>\n",
       "      <td>data science, data engineering, experience dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>create new features from raw data.</td>\n",
       "      <td>Case Study: Model Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>15</td>\n",
       "      <td>data visualization, large datasets, experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>apply feature selection techniques.</td>\n",
       "      <td>Case Study: Model Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>16</td>\n",
       "      <td>machine learning, learning techniques, learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>make predictive models using data science tech...</td>\n",
       "      <td>Case Study: Model Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>identify common fallacies and know how to avoi...</td>\n",
       "      <td>Case Study: Model Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>18</td>\n",
       "      <td>working people, problem solving, lifestyle cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>identify the different types and sources of data.</td>\n",
       "      <td>Big Data and Software Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>15</td>\n",
       "      <td>data visualization, large datasets, experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>understand different database concepts.</td>\n",
       "      <td>Big Data and Software Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>7</td>\n",
       "      <td>relational databases, experience sql, knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>build new database structures.</td>\n",
       "      <td>Big Data and Software Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>7</td>\n",
       "      <td>relational databases, experience sql, knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>evaluate various data storage frameworks w.r.t...</td>\n",
       "      <td>Big Data and Software Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>15</td>\n",
       "      <td>data visualization, large datasets, experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>analyze which data format to use for a given p...</td>\n",
       "      <td>Big Data and Software Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>15</td>\n",
       "      <td>data visualization, large datasets, experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>create a distributed computing environment for...</td>\n",
       "      <td>Big Data and Software Engineering</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>3</td>\n",
       "      <td>software development, software engineering, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>evaluate different manufacturing methods again...</td>\n",
       "      <td>Smart Manufacturing Methods and Industrial Aut...</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>define and design modern additive techniques i...</td>\n",
       "      <td>Smart Manufacturing Methods and Industrial Aut...</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>3</td>\n",
       "      <td>software development, software engineering, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>assess and estimate the impact of current tren...</td>\n",
       "      <td>Smart Manufacturing Methods and Industrial Aut...</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>8</td>\n",
       "      <td>product teams, support identifying, identifyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>apply  modern  processes  like  rapid  prototy...</td>\n",
       "      <td>Smart Manufacturing Methods and Industrial Aut...</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>3</td>\n",
       "      <td>software development, software engineering, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>explain and recognize the main components of a...</td>\n",
       "      <td>Applied Autonomous Driving</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>3</td>\n",
       "      <td>software development, software engineering, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>distinguish the sensor solutions for a self-dr...</td>\n",
       "      <td>Applied Autonomous Driving</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>11</td>\n",
       "      <td>develop processes, processes tools, tools moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>model and implement a simple motion control sy...</td>\n",
       "      <td>Applied Autonomous Driving</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>3</td>\n",
       "      <td>software development, software engineering, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>manage the main communication protocols to ret...</td>\n",
       "      <td>Applied Autonomous Driving</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>3</td>\n",
       "      <td>software development, software engineering, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>reflect on the social impact of self-driving c...</td>\n",
       "      <td>Applied Autonomous Driving</td>\n",
       "      <td>DS_60</td>\n",
       "      <td>18</td>\n",
       "      <td>working people, problem solving, lifestyle cur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            objective  \\\n",
       "0   understand the fundamental building blocks of ...   \n",
       "1   analyze stochastic data in terms of the underl...   \n",
       "2             utilize Bayesian statistics techniques.   \n",
       "3   summarize the properties of observed data usin...   \n",
       "4   apply data visualization techniques to design ...   \n",
       "5   evaluate model parameters using parameter esti...   \n",
       "6   create hypothesis tests to discriminate betwee...   \n",
       "7   analyze use cases and their requirements regar...   \n",
       "8      apply common metrics to evaluate predictions.    \n",
       "9   evaluate key performance indicators to asses p...   \n",
       "10  create monitoring tools that can be used to co...   \n",
       "11  understand common fallacies and how to avoid t...   \n",
       "12  identify current research trends and topics in...   \n",
       "13  outline a selected topic in the form of a writ...   \n",
       "14  explain relevant assumptions and design choice...   \n",
       "15  relate the chosen topic to comparable approaches.   \n",
       "16  name and describe potential applications for t...   \n",
       "17     know different machine learning model classes.   \n",
       "18  comprehend the difference between supervised, ...   \n",
       "19         understand common machine learning models.   \n",
       "20  analyze trade-offs in the application of diffe...   \n",
       "21  appropriately choose machine learning models a...   \n",
       "22  comprehend the fundamental building blocks of ...   \n",
       "23              understand concepts in deep learning.   \n",
       "24  analyze the relevant deep learning architectur...   \n",
       "25                       create deep learning models.   \n",
       "26  utilize alternative methods to train deep lear...   \n",
       "27     understand current data science methodologies.   \n",
       "28  devaluate the quality of the data used in data...   \n",
       "29                 create new features from raw data.   \n",
       "30                apply feature selection techniques.   \n",
       "31  make predictive models using data science tech...   \n",
       "32  identify common fallacies and know how to avoi...   \n",
       "33  identify the different types and sources of data.   \n",
       "34            understand different database concepts.   \n",
       "35                     build new database structures.   \n",
       "36  evaluate various data storage frameworks w.r.t...   \n",
       "37  analyze which data format to use for a given p...   \n",
       "38  create a distributed computing environment for...   \n",
       "39  evaluate different manufacturing methods again...   \n",
       "40  define and design modern additive techniques i...   \n",
       "41  assess and estimate the impact of current tren...   \n",
       "42  apply  modern  processes  like  rapid  prototy...   \n",
       "43  explain and recognize the main components of a...   \n",
       "44  distinguish the sensor solutions for a self-dr...   \n",
       "45  model and implement a simple motion control sy...   \n",
       "46  manage the main communication protocols to ret...   \n",
       "47  reflect on the social impact of self-driving c...   \n",
       "\n",
       "                                               module study_program  clusters  \\\n",
       "0                                Advanced Statistics          DS_60        11   \n",
       "1                                Advanced Statistics          DS_60        11   \n",
       "2                                Advanced Statistics          DS_60        11   \n",
       "3                                Advanced Statistics          DS_60        11   \n",
       "4                                Advanced Statistics          DS_60        15   \n",
       "5                                Advanced Statistics          DS_60        11   \n",
       "6                                Advanced Statistics          DS_60        11   \n",
       "7                            Use Case and Evaluation          DS_60        17   \n",
       "8                            Use Case and Evaluation          DS_60        11   \n",
       "9                            Use Case and Evaluation          DS_60        17   \n",
       "10                           Use Case and Evaluation          DS_60        11   \n",
       "11                           Use Case and Evaluation          DS_60        18   \n",
       "12           Seminar: Current Topics in Data Science          DS_60        13   \n",
       "13           Seminar: Current Topics in Data Science          DS_60        18   \n",
       "14           Seminar: Current Topics in Data Science          DS_60        18   \n",
       "15           Seminar: Current Topics in Data Science          DS_60        11   \n",
       "16           Seminar: Current Topics in Data Science          DS_60        17   \n",
       "17                                  Machine Learning          DS_60        16   \n",
       "18                                  Machine Learning          DS_60        16   \n",
       "19                                  Machine Learning          DS_60        16   \n",
       "20                                  Machine Learning          DS_60        11   \n",
       "21                                  Machine Learning          DS_60        16   \n",
       "22                                     Deep Learning          DS_60        16   \n",
       "23                                     Deep Learning          DS_60        16   \n",
       "24                                     Deep Learning          DS_60        16   \n",
       "25                                     Deep Learning          DS_60        16   \n",
       "26                                     Deep Learning          DS_60        16   \n",
       "27                     Case Study: Model Engineering          DS_60        13   \n",
       "28                     Case Study: Model Engineering          DS_60        13   \n",
       "29                     Case Study: Model Engineering          DS_60        15   \n",
       "30                     Case Study: Model Engineering          DS_60        16   \n",
       "31                     Case Study: Model Engineering          DS_60        11   \n",
       "32                     Case Study: Model Engineering          DS_60        18   \n",
       "33                 Big Data and Software Engineering          DS_60        15   \n",
       "34                 Big Data and Software Engineering          DS_60         7   \n",
       "35                 Big Data and Software Engineering          DS_60         7   \n",
       "36                 Big Data and Software Engineering          DS_60        15   \n",
       "37                 Big Data and Software Engineering          DS_60        15   \n",
       "38                 Big Data and Software Engineering          DS_60         3   \n",
       "39  Smart Manufacturing Methods and Industrial Aut...         DS_60        11   \n",
       "40  Smart Manufacturing Methods and Industrial Aut...         DS_60         3   \n",
       "41  Smart Manufacturing Methods and Industrial Aut...         DS_60         8   \n",
       "42  Smart Manufacturing Methods and Industrial Aut...         DS_60         3   \n",
       "43                        Applied Autonomous Driving          DS_60         3   \n",
       "44                        Applied Autonomous Driving          DS_60        11   \n",
       "45                        Applied Autonomous Driving          DS_60         3   \n",
       "46                        Applied Autonomous Driving          DS_60         3   \n",
       "47                        Applied Autonomous Driving          DS_60        18   \n",
       "\n",
       "                                          bigrams_k20  \n",
       "0   develop processes, processes tools, tools moni...  \n",
       "1   develop processes, processes tools, tools moni...  \n",
       "2   develop processes, processes tools, tools moni...  \n",
       "3   develop processes, processes tools, tools moni...  \n",
       "4   data visualization, large datasets, experience...  \n",
       "5   develop processes, processes tools, tools moni...  \n",
       "6   develop processes, processes tools, tools moni...  \n",
       "7   multiple projects, r&d projects, project team,...  \n",
       "8   develop processes, processes tools, tools moni...  \n",
       "9   multiple projects, r&d projects, project team,...  \n",
       "10  develop processes, processes tools, tools moni...  \n",
       "11  working people, problem solving, lifestyle cur...  \n",
       "12  data science, data engineering, experience dat...  \n",
       "13  working people, problem solving, lifestyle cur...  \n",
       "14  working people, problem solving, lifestyle cur...  \n",
       "15  develop processes, processes tools, tools moni...  \n",
       "16  multiple projects, r&d projects, project team,...  \n",
       "17  machine learning, learning techniques, learnin...  \n",
       "18  machine learning, learning techniques, learnin...  \n",
       "19  machine learning, learning techniques, learnin...  \n",
       "20  develop processes, processes tools, tools moni...  \n",
       "21  machine learning, learning techniques, learnin...  \n",
       "22  machine learning, learning techniques, learnin...  \n",
       "23  machine learning, learning techniques, learnin...  \n",
       "24  machine learning, learning techniques, learnin...  \n",
       "25  machine learning, learning techniques, learnin...  \n",
       "26  machine learning, learning techniques, learnin...  \n",
       "27  data science, data engineering, experience dat...  \n",
       "28  data science, data engineering, experience dat...  \n",
       "29  data visualization, large datasets, experience...  \n",
       "30  machine learning, learning techniques, learnin...  \n",
       "31  develop processes, processes tools, tools moni...  \n",
       "32  working people, problem solving, lifestyle cur...  \n",
       "33  data visualization, large datasets, experience...  \n",
       "34  relational databases, experience sql, knowledg...  \n",
       "35  relational databases, experience sql, knowledg...  \n",
       "36  data visualization, large datasets, experience...  \n",
       "37  data visualization, large datasets, experience...  \n",
       "38  software development, software engineering, be...  \n",
       "39  develop processes, processes tools, tools moni...  \n",
       "40  software development, software engineering, be...  \n",
       "41  product teams, support identifying, identifyin...  \n",
       "42  software development, software engineering, be...  \n",
       "43  software development, software engineering, be...  \n",
       "44  develop processes, processes tools, tools moni...  \n",
       "45  software development, software engineering, be...  \n",
       "46  software development, software engineering, be...  \n",
       "47  working people, problem solving, lifestyle cur...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3270101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "for i in range(1,21):\n",
    "    if i not in clusters:\n",
    "        missing.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05b3e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 6, 9, 10, 12, 14, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a58dd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 experience demonstrated, scientific journals,, scientific cv, cv contact, contact details;, scientific results, present scientific, scientific technical, drug discovery, discovery early, \n",
      "--------------------\n",
      "Cluster 2 team player, ability work, communication skills, team environment, excellent communication, collaboration skills, skills ability, within team, communication teamwork, good communication, \n",
      "--------------------\n",
      "Cluster 4 communication skills, skills excellent, excellent communication, written communication, verbal written, skills good, good communication, communication skills,, strong communication, verbal communication, \n",
      "--------------------\n",
      "Cluster 5 fluent english, english fluent, written spoken, spoken english, english fluency, fluent written, english skills, language skills, excellent written, written verbal, \n",
      "--------------------\n",
      "Cluster 6 career development, willingness learn, new technologies, learn new, genuine willingness, learn drive, dedicated house, house l&d, l&d department,, department, access, \n",
      "--------------------\n",
      "Cluster 9 computer science,, degree computer, science, mathematics,, master’s degree, phd computer, related field, computer science, quantitative field, statistics, engineering,, engineering, computer, \n",
      "--------------------\n",
      "Cluster 10 flexible working, work environment, working hours, environment flexible, working environment, flexible work, dynamic work, work home, hours flexible, large degree, \n",
      "--------------------\n",
      "Cluster 12 competitive salary, competitive compensation, salary competitive, compensation package, package competitive, benefits package, including performance, social benefits, benefits competitive, competitive remuneration, \n",
      "--------------------\n",
      "Cluster 14 international environment, work environment, relocation packages, city center, great job,, job, international, willing travel, relocation support, flexible enthusiastic, enthusiastic work, \n",
      "--------------------\n",
      "Cluster 19 programming languages, languages python,, programming skills, python data, programming experience, python, r,, data analysis, proficient python, data science, languages (python,, \n",
      "--------------------\n",
      "Cluster 20 experience cloud, google cloud, cloud platform, experience working, ms azure, platform technology, technology (aws, (aws ms, ms azure), cloud services, \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for miss in missing:\n",
    "    print(\"Cluster \"+str(miss)+\" \"+k20_bigrams[miss])\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73377a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
