{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:324: UserWarning: Trying to unpickle estimator KMeans from version 0.23.1 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, redirect, url_for\n",
    "from flask_bootstrap import Bootstrap\n",
    "from flask_wtf import FlaskForm\n",
    "from wtforms import StringField, SubmitField\n",
    "from wtforms.validators import DataRequired\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "from fpdf import FPDF\n",
    "from flask import send_file\n",
    "import fpdf\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import plotly as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "k31_full = pickle.load(open('docker/k_31_full', 'rb'))\n",
    "cluster_label_bigrams = pickle.load(open('docker/cluster_label_bigrams','rb')) \n",
    "cluster_importance = pickle.load(open('docker/cluster_importance', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"text/intro.txt\")\n",
    "intro = file.read().replace(\"\\n\", \" \")\n",
    "intro = intro.encode('latin-1', 'replace').decode('latin-1')\n",
    "file.close()\n",
    "\n",
    "file = open(\"text/plot_explanation.txt\")\n",
    "plot_explanation = file.read().replace(\"\\n\", \" \")\n",
    "plot_explanation = plot_explanation.encode('latin-1', 'replace').decode('latin-1')\n",
    "file.close()\n",
    "\n",
    "file = open(\"text/per_skill_description.txt\")\n",
    "per_skill_description = file.read().replace(\"/n\", \" \")\n",
    "per_skill_description = per_skill_description.encode('latin-1', 'replace').decode('latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_pdf(skills):\n",
    "    analysis = get_plot(skills)\n",
    "    plot = analysis[0]\n",
    "    df = analysis[1]\n",
    "    plot.write_image(\"fig1.png\", scale=1)#, width=500, height=750)\n",
    "    \n",
    "    pdf=FPDF('P', 'mm', 'A4')\n",
    "    pdf.add_page()\n",
    "    \n",
    "    pdf.set_font('Arial', 'B', 14) #setting font for title\n",
    "    pdf.cell(40, 0, 'Data Scientist CV Review Report', ln=2) #Write Title\n",
    "    pdf.set_font('Arial', '', 9) #setting font for text cells\n",
    "    pdf.set_xy(10,15) #place cursor\n",
    "    pdf.multi_cell(w=190, h=5, txt=intro, align='J')\n",
    "    \n",
    "    pdf.set_xy(pdf.get_x(), pdf.get_y()+5)\n",
    "    pdf.set_font('Arial', 'B', 11) #setting font for title\n",
    "    pdf.cell(40, 0, 'Comparrison Plot', ln=2) #Write Title\n",
    "    pdf.set_font('Arial', '', 9)\n",
    "    pdf.set_xy(pdf.get_x(), pdf.get_y()+5)\n",
    "    pdf.multi_cell(w=190, h=5, txt=plot_explanation)\n",
    "    \n",
    "    pdf.image('fig1.png', w=200)#x = pdf.get_x, y = 15, w = 200)#, h = 200, type = '', link = '')\n",
    "    \n",
    "    pdf.add_page()\n",
    "    pdf.set_font('Arial', 'B', 11) #setting font for title\n",
    "    pdf.cell(40, 0, 'Analysis per input skill', ln=2) #Write Title\n",
    "    pdf.set_font('Arial', '', 9)\n",
    "    pdf.set_xy(pdf.get_x(), pdf.get_y()+5)\n",
    "    pdf.multi_cell(w=190, h=5, txt=per_skill_description)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text = \"Input skill \"+row['skill']+\" was clustered in cluster \"+str(row['cluster'])+\\\n",
    "        \" which contains skills regarding \"+cluster_label_bigrams[row['cluster']]+\\\n",
    "        \". The score for this skille is \"+str(row['score'])+\".\\n\\n\"\n",
    "        text = text.encode('latin-1', 'replace').decode('latin-1')\n",
    "        pdf.multi_cell(w=190, h=5, txt = text)\n",
    "    \n",
    "    return pdf\n",
    "skills = ['programming skills','computer science','experience as a software developer','using git and github','machine learning techniques']\n",
    "pdf = return_pdf(skills)\n",
    "pdf.output('report.pdf', 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot(cv): #takes in list of skills and returns a plot with score for each cluster\n",
    "    df_sim = pd.DataFrame()\n",
    "    df_sim['cluster'] = range(len(k31_full.cluster_centers_))\n",
    "    \n",
    "    labels = cluster_label_bigrams\n",
    "    importance = cluster_importance\n",
    "    \n",
    "    model = 'all-distilroberta-v1'\n",
    "    model = SentenceTransformer(model)\n",
    "    embeddings_cv = model.encode(cv)\n",
    "    embeddings_f = embeddings_cv.astype(float)\n",
    "    clusters_cv = k31_full.predict(embeddings_f)\n",
    "    clusters_cv_l  = clusters_cv.tolist()\n",
    "    \n",
    "    cv_scores = []\n",
    "    \n",
    "    for i, cluster in enumerate(clusters_cv):\n",
    "        cv_scores.append(util.pytorch_cos_sim(k31_full.cluster_centers_[cluster], embeddings_f[i]).item())\n",
    "    \n",
    "    df_report = pd.DataFrame()\n",
    "    df_report['skill']=cv\n",
    "    df_report['cluster']=clusters_cv_l\n",
    "    df_report['score']=cv_scores\n",
    "    \n",
    "    scores = []\n",
    "    for cluster in range(len(k31_full.cluster_centers_)):\n",
    "        if cluster not in clusters_cv_l:\n",
    "            scores.append(0)\n",
    "        else:\n",
    "            score = 0\n",
    "            indexes = np.where(clusters_cv==cluster)[0]\n",
    "            for i in indexes:\n",
    "                if cv_scores[i] > score:\n",
    "                    score = cv_scores[i]\n",
    "            scores.append(score)   \n",
    "    \n",
    "    df_sim['score'] = scores\n",
    "    df_sim['importance'] = importance\n",
    "    df_sim['labels'] = labels\n",
    "    \n",
    "    df_sim['CV_similarity'] = df_sim['importance']*df_sim['score']\n",
    "    df_sim['Importance_Cluster_in_Job_Postings'] = df_sim['importance']-df_sim['CV_similarity']\n",
    "    df_sim = df_sim.sort_values('importance')\n",
    "    \n",
    "    fig = px.bar(df_sim, y='labels', x=[\"CV_similarity\",\"Importance_Cluster_in_Job_Postings\"], hover_data = ['importance'])\n",
    "    fig.update_layout(height=2*300, width=3*300, \\\n",
    "                          #font=dict(size=10),\\\n",
    "                          title = 'Input CV Similarity to Requirements in Job Postings',\\\n",
    "                          barmode='stack', \\\n",
    "                          yaxis_title=\"Common Bigrams in Cluster\",\\\n",
    "                          xaxis_title=\"CV Similarity to Cluster\")\n",
    "    return fig, df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
