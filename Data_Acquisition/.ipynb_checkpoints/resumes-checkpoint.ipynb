{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95161c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "00bc7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtale\n",
    "#handy pandas visualizer, when on local Jupyter Server just run dtale.show(df)\n",
    "#from Docker container visual is available at http://localhost:40000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "92f996c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../datasets/resume_samples.txt'\n",
    "df = pd.DataFrame()\n",
    "counter = 0\n",
    "id_list = []\n",
    "title_list = []\n",
    "skill_list = []\n",
    "#exp_list = []\n",
    "with open(path, 'r',encoding=\"utf8\", errors='backslashreplace') as f:\n",
    "    for line in f.readlines():\n",
    "        \n",
    "        splitted = line.split(':::')\n",
    "        title = splitted[1].split(';')[0]\n",
    "        if 'data scientist' in title.lower():\n",
    "            splitted = splitted[2].lower()\n",
    "            splitted = splitted.replace('\\\\xa0',';;;')\n",
    "            splitted = splitted.replace('*',';;;')\n",
    "            splitted = splitted.replace('\\\\x95',';;;')\n",
    "            splitted = splitted.replace('education',';;;')\n",
    "            splitted = splitted.replace(',',';;;')\n",
    "            splitted = splitted.split(';;;')\n",
    "            \n",
    "            for skill in splitted[1:]:\n",
    "                if (len(skill)>1) & ('responsibilities:' not in skill.lower()):\n",
    "                    id_list.append(counter)\n",
    "                    \n",
    "                    title_list.append(title)\n",
    "                    skill_list.append(skill)\n",
    "            counter+=1\n",
    "df['id']=id_list\n",
    "df['title']=title_list\n",
    "df['skill']=skill_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "51b94ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist/Analytics Consultant</td>\n",
       "      <td>il currently a junior data scientist with a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist/Analytics Consultant</td>\n",
       "      <td>data modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist/Analytics Consultant</td>\n",
       "      <td>sql and data visualization. experienced in ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist/Analytics Consultant</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist/Analytics Consultant</td>\n",
       "      <td>parallel programming and devops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>66</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>operating systems all versions of windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18083</th>\n",
       "      <td>66</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>unix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18084</th>\n",
       "      <td>66</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18085</th>\n",
       "      <td>66</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>macintosh hd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18086</th>\n",
       "      <td>66</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>sun solaris\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18087 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                title  \\\n",
       "0       0  Data Scientist/Analytics Consultant   \n",
       "1       0  Data Scientist/Analytics Consultant   \n",
       "2       0  Data Scientist/Analytics Consultant   \n",
       "3       0  Data Scientist/Analytics Consultant   \n",
       "4       0  Data Scientist/Analytics Consultant   \n",
       "...    ..                                  ...   \n",
       "18082  66                       Data Scientist   \n",
       "18083  66                       Data Scientist   \n",
       "18084  66                       Data Scientist   \n",
       "18085  66                       Data Scientist   \n",
       "18086  66                       Data Scientist   \n",
       "\n",
       "                                                   skill  \n",
       "0       il currently a junior data scientist with a s...  \n",
       "1                                          data modeling  \n",
       "2       sql and data visualization. experienced in ma...  \n",
       "3                                            engineering  \n",
       "4                        parallel programming and devops  \n",
       "...                                                  ...  \n",
       "18082          operating systems all versions of windows  \n",
       "18083                                               unix  \n",
       "18084                                              linux  \n",
       "18085                                       macintosh hd  \n",
       "18086                                      sun solaris\\n  \n",
       "\n",
       "[18087 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "759033a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_bert(string):\n",
    "    string = string.strip(\"\\n.’:\")\n",
    "    string = string.strip(\"’\")\n",
    "    string = string.strip(\"\\\\n\")\n",
    "    string = string.replace(\"/\",\" \")\n",
    "    return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d04f77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k21 = pickle.load(open('../Experiments/k21.sav', 'rb'))\n",
    "objectives = []\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f99863d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e29da10b5b44cfb5437ff01893899c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skill_list = []\n",
    "for s in df['skill'].to_list():\n",
    "    skill_list.append(preprocess_for_bert(s))\n",
    "embeddings = model.encode(skill_list)\n",
    "clusters =  k21.predict(np.array(embeddings.tolist()))\n",
    "df['cluster']=clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bde631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k20_bigrams = pickle.load(open('../Experiments/k20_bigrams', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "90c2929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = []\n",
    "for cluster in clusters:\n",
    "    bigrams.append(k20_bigrams[cluster])\n",
    "df['bigrams_k20']=bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "650b3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=dtale.show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bdb4123c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To gain access to an instance object simply pass the value from 'ID' to dtale.get_instance(ID)\n",
      "\n",
      "ID Name                                     URL\n",
      " 1       http://584bcee9ce77:40000/dtale/main/1\n",
      "         http://584bcee9ce77:40000/dtale/main/1\n",
      " 2       http://584bcee9ce77:40000/dtale/main/2\n",
      "         http://584bcee9ce77:40000/dtale/main/2\n",
      " 3       http://584bcee9ce77:40000/dtale/main/3\n",
      "         http://584bcee9ce77:40000/dtale/main/3\n",
      " 4       http://584bcee9ce77:40000/dtale/main/4\n",
      "         http://584bcee9ce77:40000/dtale/main/4\n",
      " 5       http://584bcee9ce77:40000/dtale/main/5\n",
      "         http://584bcee9ce77:40000/dtale/main/5\n",
      " 6       http://584bcee9ce77:40000/dtale/main/6\n",
      "         http://584bcee9ce77:40000/dtale/main/6\n",
      " 7       http://584bcee9ce77:40000/dtale/main/7\n",
      "         http://584bcee9ce77:40000/dtale/main/7\n",
      " 8       http://584bcee9ce77:40000/dtale/main/8\n",
      "         http://584bcee9ce77:40000/dtale/main/8\n",
      " 9       http://584bcee9ce77:40000/dtale/main/9\n",
      "         http://584bcee9ce77:40000/dtale/main/9\n",
      "10      http://584bcee9ce77:40000/dtale/main/10\n",
      "        http://584bcee9ce77:40000/dtale/main/10\n",
      "11      http://584bcee9ce77:40000/dtale/main/11\n",
      "        http://584bcee9ce77:40000/dtale/main/11\n",
      "12      http://584bcee9ce77:40000/dtale/main/12\n",
      "        http://584bcee9ce77:40000/dtale/main/12\n",
      "13      http://584bcee9ce77:40000/dtale/main/13\n",
      "        http://584bcee9ce77:40000/dtale/main/13\n",
      "14      http://584bcee9ce77:40000/dtale/main/14\n",
      "        http://584bcee9ce77:40000/dtale/main/14\n"
     ]
    }
   ],
   "source": [
    "dtale.instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3270101e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3299 software development, software engineering, best practices, data science, experience working, processing frameworks, frameworks spark, tools (e.g., standard software, ci cd,, \n",
      "-----------------------\n",
      "15 2973 data visualization, large datasets, experience data, knowledge data, data visualisation, large data, big data, understanding data, data engineering, data pipelines, \n",
      "-----------------------\n",
      "11 2269 develop processes, processes tools, tools monitor, model performance, performance data, data accuracy, analyze data, data analysis, ability develop, develop experimental, \n",
      "-----------------------\n",
      "19 1511 programming languages, languages python,, programming skills, python data, programming experience, python, r,, data analysis, proficient python, data science, languages (python,, \n",
      "-----------------------\n",
      "18 1490 working people, problem solving, lifestyle curiosity,, curiosity, learning,, learning, sharing,, sharing, working, people share, share hunger.\"], think creatively, solve problems, \n",
      "-----------------------\n",
      "7 1183 relational databases, experience sql, knowledge sql, sql queries, experience databases, advanced sql, sql skills, experience relational, sql experience, python sql, \n",
      "-----------------------\n",
      "1 1029 experience demonstrated, scientific journals,, scientific cv, cv contact, contact details;, scientific results, present scientific, scientific technical, drug discovery, discovery early, \n",
      "-----------------------\n",
      "16 973 machine learning, learning techniques, learning algorithms, understanding machine, experience machine, deep learning, learning experience, strong knowledge, knowledge machine, machine learning,, \n",
      "-----------------------\n",
      "14 922 international environment, work environment, relocation packages, city center, great job,, job, international, willing travel, relocation support, flexible enthusiastic, enthusiastic work, \n",
      "-----------------------\n",
      "8 807 product teams, support identifying, identifying opportunities, opportunities creating, creating customer, customer value, identify opportunities, closely business, business outcomes, better understand, \n",
      "-----------------------\n",
      "17 384 multiple projects, r&d projects, project team, research partners, specific development, development projects, product engineering, engineering teams, identify trends, experience building, \n",
      "-----------------------\n",
      "20 317 experience cloud, google cloud, cloud platform, experience working, ms azure, platform technology, technology (aws, (aws ms, ms azure), cloud services, \n",
      "-----------------------\n",
      "13 271 data science, data engineering, experience data, data scientists, years experience, 5+ years, years data, science experience, data scientist, 3+ years, \n",
      "-----------------------\n",
      "0 148 teams across, key stakeholders, strong communication, communication skills, internal stakeholders, across business, ability communicate, technical non-technical, interest working, informal, dynamic, \n",
      "-----------------------\n",
      "6 133 career development, willingness learn, new technologies, learn new, genuine willingness, learn drive, dedicated house, house l&d, l&d department,, department, access, \n",
      "-----------------------\n",
      "12 133 competitive salary, competitive compensation, salary competitive, compensation package, package competitive, benefits package, including performance, social benefits, benefits competitive, competitive remuneration, \n",
      "-----------------------\n",
      "10 90 flexible working, work environment, working hours, environment flexible, working environment, flexible work, dynamic work, work home, hours flexible, large degree, \n",
      "-----------------------\n",
      "2 72 team player, ability work, communication skills, team environment, excellent communication, collaboration skills, skills ability, within team, communication teamwork, good communication, \n",
      "-----------------------\n",
      "9 43 computer science,, degree computer, science, mathematics,, master’s degree, phd computer, related field, computer science, quantitative field, statistics, engineering,, engineering, computer, \n",
      "-----------------------\n",
      "4 31 communication skills, skills excellent, excellent communication, written communication, verbal written, skills good, good communication, communication skills,, strong communication, verbal communication, \n",
      "-----------------------\n",
      "5 9 fluent english, english fluent, written spoken, spoken english, english fluency, fluent written, english skills, language skills, excellent written, written verbal, \n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#df['cluster'].value_counts()\n",
    "for c, count in df['cluster'].value_counts().iteritems():\n",
    "    print(str(c)+\" \"+str(count)+\" \"+k20_bigrams[c])\n",
    "    print('-----------------------')\n",
    "    \n",
    "for i in range(0,20):\n",
    "    if i not in df['cluster'].to_list():\n",
    "         print('missing '+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "73377a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "cluster_matrix = []\n",
    "\n",
    "for id in np.unique(df[['id']].values):\n",
    "    print(id)\n",
    "    cluster_counter = []\n",
    "    filtered = df[df['id']==id]\n",
    "    for cluster in range(0,20):\n",
    "        c=0\n",
    "        for index, row in filtered.iterrows():\n",
    "            if row['cluster']==cluster:\n",
    "                c+=1\n",
    "        cluster_counter.append(c)\n",
    "    cluster_matrix.append(cluster_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e671b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume  = pd.DataFrame()\n",
    "df_resume['id']=np.unique(df[['id']].values)\n",
    "df_resume['matrix']=cluster_matrix\n",
    "#df_resume = df_resume.append(pd.DataFrame(df_resume['matrix'].tolist()))\n",
    "foo=pd.DataFrame(df_resume['matrix'].tolist())\n",
    "df_resume = pd.concat([df_resume,foo], axis=1)\n",
    "counted = df_resume.iloc[:,2:].astype(bool).sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "94da897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>matrix</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2, 6, 2, 17, 0, 0, 1, 7, 7, 2, 0, 17, 0, 3, 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 7, 1, 0, 0, 5, 2, 1, 1, 2, 0, 1, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 5, 0, 14, 0, 0, 3, 2, 8, 0, 0, 13, 1, 1, 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[6, 3, 0, 14, 0, 0, 1, 2, 6, 0, 0, 11, 2, 5, 6...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[1, 0, 0, 18, 0, 1, 2, 1, 13, 1, 1, 6, 1, 0, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>[0, 19, 2, 108, 0, 0, 4, 8, 3, 0, 7, 11, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>[0, 12, 0, 12, 0, 0, 2, 5, 2, 1, 0, 9, 0, 3, 6...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>[0, 6, 0, 15, 0, 0, 1, 3, 7, 0, 0, 12, 1, 0, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>[2, 6, 2, 17, 0, 0, 1, 7, 7, 2, 0, 17, 0, 3, 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>[8, 28, 2, 102, 1, 1, 4, 51, 23, 0, 1, 70, 4, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>102</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             matrix  0   1  2    3  4  \\\n",
       "0    0  [2, 6, 2, 17, 0, 0, 1, 7, 7, 2, 0, 17, 0, 3, 1...  2   6  2   17  0   \n",
       "1    1  [0, 0, 0, 7, 1, 0, 0, 5, 2, 1, 1, 2, 0, 1, 3, ...  0   0  0    7  1   \n",
       "2    2  [0, 5, 0, 14, 0, 0, 3, 2, 8, 0, 0, 13, 1, 1, 8...  0   5  0   14  0   \n",
       "3    3  [6, 3, 0, 14, 0, 0, 1, 2, 6, 0, 0, 11, 2, 5, 6...  6   3  0   14  0   \n",
       "4    4  [1, 0, 0, 18, 0, 1, 2, 1, 13, 1, 1, 6, 1, 0, 2...  1   0  0   18  0   \n",
       "..  ..                                                ... ..  .. ..  ... ..   \n",
       "62  62  [0, 19, 2, 108, 0, 0, 4, 8, 3, 0, 7, 11, 1, 1,...  0  19  2  108  0   \n",
       "63  63  [0, 12, 0, 12, 0, 0, 2, 5, 2, 1, 0, 9, 0, 3, 6...  0  12  0   12  0   \n",
       "64  64  [0, 6, 0, 15, 0, 0, 1, 3, 7, 0, 0, 12, 1, 0, 1...  0   6  0   15  0   \n",
       "65  65  [2, 6, 2, 17, 0, 0, 1, 7, 7, 2, 0, 17, 0, 3, 1...  2   6  2   17  0   \n",
       "66  66  [8, 28, 2, 102, 1, 1, 4, 51, 23, 0, 1, 70, 4, ...  8  28  2  102  1   \n",
       "\n",
       "    5  6   7  ...  10  11  12  13  14   15  16  17  18  19  \n",
       "0   0  1   7  ...   0  17   0   3  11   11   5   4   7   7  \n",
       "1   0  0   5  ...   1   2   0   1   3    4   0   0   3   0  \n",
       "2   0  3   2  ...   0  13   1   1   8    5   6   1   9   5  \n",
       "3   0  1   2  ...   0  11   2   5   6   10   0   1   1   3  \n",
       "4   1  2   1  ...   1   6   1   0   2    4   0   1   2   1  \n",
       ".. .. ..  ..  ...  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  \n",
       "62  0  4   8  ...   7  11   1   1  19   29  22   8  11   7  \n",
       "63  0  2   5  ...   0   9   0   3   6   12   4   1  13   7  \n",
       "64  0  1   3  ...   0  12   1   0  10   10   5   1   6  10  \n",
       "65  0  1   7  ...   0  17   0   3  11   11   5   4   7   7  \n",
       "66  1  4  51  ...   1  70   4   8  22  102  24  11  38  31  \n",
       "\n",
       "[67 rows x 22 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7ea6bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 18 was present in 100.0% of all resumes. Most common bigrams of this cluster are working people, problem solving, lifestyle curiosity,, curiosity, learning,, learning, sharing,, sharing, working, people share, share hunger.\"], think creatively, solve problems, \n",
      "---------------------\n",
      "cluster 3 was present in 100.0% of all resumes. Most common bigrams of this cluster are software development, software engineering, best practices, data science, experience working, processing frameworks, frameworks spark, tools (e.g., standard software, ci cd,, \n",
      "---------------------\n",
      "cluster 14 was present in 100.0% of all resumes. Most common bigrams of this cluster are international environment, work environment, relocation packages, city center, great job,, job, international, willing travel, relocation support, flexible enthusiastic, enthusiastic work, \n",
      "---------------------\n",
      "cluster 19 was present in 98.50746268656717% of all resumes. Most common bigrams of this cluster are programming languages, languages python,, programming skills, python data, programming experience, python, r,, data analysis, proficient python, data science, languages (python,, \n",
      "---------------------\n",
      "cluster 7 was present in 98.50746268656717% of all resumes. Most common bigrams of this cluster are relational databases, experience sql, knowledge sql, sql queries, experience databases, advanced sql, sql skills, experience relational, sql experience, python sql, \n",
      "---------------------\n",
      "cluster 15 was present in 98.50746268656717% of all resumes. Most common bigrams of this cluster are data visualization, large datasets, experience data, knowledge data, data visualisation, large data, big data, understanding data, data engineering, data pipelines, \n",
      "---------------------\n",
      "cluster 11 was present in 98.50746268656717% of all resumes. Most common bigrams of this cluster are develop processes, processes tools, tools monitor, model performance, performance data, data accuracy, analyze data, data analysis, ability develop, develop experimental, \n",
      "---------------------\n",
      "cluster 1 was present in 97.01492537313433% of all resumes. Most common bigrams of this cluster are experience demonstrated, scientific journals,, scientific cv, cv contact, contact details;, scientific results, present scientific, scientific technical, drug discovery, discovery early, \n",
      "---------------------\n",
      "cluster 8 was present in 94.02985074626866% of all resumes. Most common bigrams of this cluster are product teams, support identifying, identifying opportunities, opportunities creating, creating customer, customer value, identify opportunities, closely business, business outcomes, better understand, \n",
      "---------------------\n",
      "cluster 16 was present in 92.53731343283582% of all resumes. Most common bigrams of this cluster are machine learning, learning techniques, learning algorithms, understanding machine, experience machine, deep learning, learning experience, strong knowledge, knowledge machine, machine learning,, \n",
      "---------------------\n",
      "cluster 17 was present in 91.04477611940298% of all resumes. Most common bigrams of this cluster are multiple projects, r&d projects, project team, research partners, specific development, development projects, product engineering, engineering teams, identify trends, experience building, \n",
      "---------------------\n",
      "cluster 13 was present in 88.05970149253731% of all resumes. Most common bigrams of this cluster are data science, data engineering, experience data, data scientists, years experience, 5+ years, years data, science experience, data scientist, 3+ years, \n",
      "---------------------\n",
      "cluster 6 was present in 82.08955223880598% of all resumes. Most common bigrams of this cluster are career development, willingness learn, new technologies, learn new, genuine willingness, learn drive, dedicated house, house l&d, l&d department,, department, access, \n",
      "---------------------\n",
      "cluster 0 was present in 74.6268656716418% of all resumes. Most common bigrams of this cluster are teams across, key stakeholders, strong communication, communication skills, internal stakeholders, across business, ability communicate, technical non-technical, interest working, informal, dynamic, \n",
      "---------------------\n",
      "cluster 12 was present in 61.19402985074627% of all resumes. Most common bigrams of this cluster are competitive salary, competitive compensation, salary competitive, compensation package, package competitive, benefits package, including performance, social benefits, benefits competitive, competitive remuneration, \n",
      "---------------------\n",
      "cluster 2 was present in 61.19402985074627% of all resumes. Most common bigrams of this cluster are team player, ability work, communication skills, team environment, excellent communication, collaboration skills, skills ability, within team, communication teamwork, good communication, \n",
      "---------------------\n",
      "cluster 10 was present in 61.19402985074627% of all resumes. Most common bigrams of this cluster are flexible working, work environment, working hours, environment flexible, working environment, flexible work, dynamic work, work home, hours flexible, large degree, \n",
      "---------------------\n",
      "cluster 9 was present in 52.23880597014925% of all resumes. Most common bigrams of this cluster are computer science,, degree computer, science, mathematics,, master’s degree, phd computer, related field, computer science, quantitative field, statistics, engineering,, engineering, computer, \n",
      "---------------------\n",
      "cluster 4 was present in 32.83582089552239% of all resumes. Most common bigrams of this cluster are communication skills, skills excellent, excellent communication, written communication, verbal written, skills good, good communication, communication skills,, strong communication, verbal communication, \n",
      "---------------------\n",
      "cluster 5 was present in 10.44776119402985% of all resumes. Most common bigrams of this cluster are fluent english, english fluent, written spoken, spoken english, english fluency, fluent written, english skills, language skills, excellent written, written verbal, \n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "for cluster, count in counted.iteritems():\n",
    "    print(\"cluster \"+str(cluster)+\" was present in \"+str(count/len(df_resume)*100)+\"% of all resumes. Most common bigrams of this cluster are \"+k20_bigrams[cluster])\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13f106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
